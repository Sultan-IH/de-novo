{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from statistics import stdev, mean\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPU = 3\n",
    "SEED = 3287450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.empty_cache()\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(thing, path):\n",
    "    with open(path, 'wb') as fp:\n",
    "        pkl.dump(thing, fp)\n",
    "    print(f'saved [{type(thing)}] to {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipinski\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smiles(path, test_split=0.15):\n",
    "    all_smiles = []\n",
    "    with open(path) as fp:\n",
    "        for line in fp.readlines():\n",
    "            all_smiles += [GO_TOKEN + line]\n",
    "    return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = Path('./data/lipinski/druglike_lipinski_100k.smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_TOKEN = 'G'\n",
    "END_TOKEN = '\\n'\n",
    "PAD_TOKEN = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SMILES = []\n",
    "with data_file.open() as fp:\n",
    "    for line in fp.readlines():\n",
    "        ALL_SMILES += [GO_TOKEN + line]\n",
    "NUM_TOTAL = len(ALL_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.15\n",
    "split = int(NUM_TOTAL*TEST_SPLIT)\n",
    "TRAIN_SMILES = ALL_SMILES[split:]\n",
    "TEST_SMILES = ALL_SMILES[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85000, 15000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_SMILES), len(TEST_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list(set(''.join(ALL_SMILES+[PAD_TOKEN])))\n",
    "NUM_SYM = len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYM_TO_ID = {s:i for i,s in enumerate(alphabet)}\n",
    "ID_TO_SYM = {i:s for s,i in SYM_TO_ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{')': 0,\n",
       " 'C': 1,\n",
       " ']': 2,\n",
       " 'A': 3,\n",
       " 'F': 4,\n",
       " 'l': 5,\n",
       " '#': 6,\n",
       " 'O': 7,\n",
       " 'o': 8,\n",
       " '1': 9,\n",
       " '3': 10,\n",
       " '-': 11,\n",
       " 'N': 12,\n",
       " '4': 13,\n",
       " 's': 14,\n",
       " '/': 15,\n",
       " 'S': 16,\n",
       " 'P': 17,\n",
       " '(': 18,\n",
       " 'c': 19,\n",
       " '\\n': 20,\n",
       " 'I': 21,\n",
       " '+': 22,\n",
       " '6': 23,\n",
       " '7': 24,\n",
       " 'B': 25,\n",
       " 'p': 26,\n",
       " 'r': 27,\n",
       " '2': 28,\n",
       " '=': 29,\n",
       " '8': 30,\n",
       " '@': 31,\n",
       " 'H': 32,\n",
       " 'n': 33,\n",
       " 'G': 34,\n",
       " '[': 35,\n",
       " '\\\\': 36,\n",
       " '5': 37}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYM_TO_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAX_ATOMS = max(map(lambda s: Chem.MolFromSmiles(s).GetNumAtoms(), D.keys()))\n",
    "MAX_SYM = max(map(len, ALL_SMILES)) # GO_TOKEN and END_TOKEN already considered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 100000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SYM, NUM_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(smiles):\n",
    "    \"\"\"\n",
    "    encode(simles): \n",
    "        - takes in a variable length smiles string (up to MAX_SYM) \n",
    "          and outputs a fixed size vector (MAX_SYM by NUM_SYM)\n",
    "        \n",
    "    \"\"\"\n",
    "    x = np.zeros((MAX_SYM, NUM_SYM))\n",
    "    x_n = len(smiles)\n",
    "    for i, sym in enumerate(smiles):\n",
    "        x[i, SYM_TO_ID[sym]] = 1\n",
    "    x[x_n:, SYM_TO_ID[PAD_TOKEN]] = 1\n",
    "    return x, x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "    assert x.shape[1] == NUM_SYM\n",
    "    smiles = ''\n",
    "    for i in range(x.shape[0]):\n",
    "        topi = np.argmax(x[i, :])\n",
    "        smiles += ID_TO_SYM[topi]\n",
    "    return smiles if smiles[0] != 'G' else smiles[1:]\n",
    "\n",
    "def decode_short(x):\n",
    "    s = decode(x)\n",
    "    return  s[:s.find(END_TOKEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cc1onc(NC(=O)c2ccc(Cl)cc2Cl)c1Br\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(ALL_SMILES[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cc1onc(NC(=O)c2ccc(Cl)cc2Cl)c1Br'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_short(encode(ALL_SMILES[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, smiles):\n",
    "        self.all_smiles = smiles\n",
    "        self.size = len(smiles)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        __getitem__(self, i):\n",
    "            - return \n",
    "        \"\"\"\n",
    "        x_i, x_n = encode(self.all_smiles[i])\n",
    "        \n",
    "        y_i = x_i[1:].copy()\n",
    "        x_i = x_i[:-1].copy()\n",
    "        \n",
    "        return x_i, y_i, x_n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMILESDataset(TRAIN_SMILES)\n",
    "test_dataset = SMILESDataset(TEST_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xi, yi, xlen = train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CC(C)Oc1ccc(cc1)c2cc(NCC(O)CO)c3ccccc3n2\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA',\n",
       " 'CC(C)Oc1ccc(cc1)c2cc(NCC(O)CO)c3ccccc3n2\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(xi), decode(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi, yi, xlen = test_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FC(F)(F)Oc1cccc(NC(=O)c2oc(Br)cc2)c1\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA',\n",
       " 'FC(F)(F)Oc1cccc(NC(=O)c2oc(Br)cc2)c1\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(xi), decode(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_CPU, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, num_workers=NUM_CPU, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid(smiles):\n",
    "    \"\"\"\n",
    "    count_valid(smiles):\n",
    "        - returns % of valid smiles\n",
    "    \"\"\"\n",
    "    invalid = 0\n",
    "    \n",
    "    for m in map(Chem.MolFromSmiles, smiles):\n",
    "        invalid += m is None\n",
    "        \n",
    "    return 1 - (invalid/len(smiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain LSTM model\n",
    "class GeneratorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=0.15)\n",
    "        \n",
    "        self.input_module = nn.Sequential(nn.Linear(input_size, 256),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.10),\n",
    "                                         nn.Linear(256, 512),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.10),\n",
    "                                         nn.Linear(512, embedding_size),\n",
    "                                         nn.ReLU())\n",
    "        \n",
    "        self.output_module = nn.Sequential(nn.Linear(hidden_size, 256),\n",
    "                                           nn.Dropout(0.10),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(256, output_size))\n",
    "\n",
    "        self.hidden = None \n",
    "\n",
    "    def init_hidden(self, batch_size, cuda=True):\n",
    "        ht = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        ct = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        if cuda:\n",
    "            return ht.cuda(), ct.cuda()\n",
    "        else:\n",
    "            return ht, ct\n",
    "\n",
    "    def forward(self, input_raw, pack=False, input_lens=None):\n",
    "        \"\"\"\n",
    "        forward(self, input_raw, state):\n",
    "             - input_raw = (bs, x_{i,t})\n",
    "             - state = (ht, ct)\n",
    "        \"\"\"\n",
    "        input_ = self.input_module(input_raw)\n",
    "        \n",
    "        if pack:\n",
    "            input_ = pack_padded_sequence(input_, input_lens, batch_first=True)\n",
    "            \n",
    "        input_, self.hidden = self.lstm(input_, self.hidden)\n",
    "        \n",
    "        if pack: \n",
    "            input_ = pad_packed_sequence(input_, batch_first=True)[0]\n",
    "\n",
    "            \n",
    "        input_ = self.output_module(input_)\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GeneratorLSTM(input_size = NUM_SYM, \n",
    "                      output_size = NUM_SYM, \n",
    "                      num_layers = 3, \n",
    "                      hidden_size = 512, \n",
    "                      embedding_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorLSTM(\n",
       "  (lstm): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.15)\n",
       "  (input_module): Sequential(\n",
       "    (0): Linear(in_features=38, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (output_module): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = optim.Adam(list(model.parameters()), lr=3e-3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorLSTM(\n",
       "  (lstm): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.15)\n",
       "  (input_module): Sequential(\n",
       "    (0): Linear(in_features=38, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (output_module): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has [6,849,062] trainable params\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'model has [{count_parameters(model):,}] trainable params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, model_optim, dataloader, \n",
    "                    test_interval):\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    loss_history = []\n",
    "    total = len(dataloader)\n",
    "    \n",
    "    test_loss_history = defaultdict(list)\n",
    "    new_smiles = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for batch_idx, batch in tqdm(enumerate(dataloader), total=total):\n",
    "        \n",
    "        if batch_idx % test_interval == 0:\n",
    "            new_smiles[f'[batch num {batch_idx}] topk'] = generate(model)\n",
    "            new_smiles[f'[batch num {batch_idx}] softmax sample'] = generate(model, sample_f=softmax_temp_sample)\n",
    "            \n",
    "            smiles_valid_batch = generate(model, test_samples=100, sample_f=softmax_temp_sample, v=False)\n",
    "            validity = count_valid(smiles_valid_batch)\n",
    "            \n",
    "            test_loss_history[batch_idx] = test(model, testloader)\n",
    "            # we can test later\n",
    "            \n",
    "            print(f'[batch num: {batch_idx}] sampled; [{validity:.3f}%] valid smiles sampled')\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                print_loss = 'nan'\n",
    "            else:\n",
    "                print_loss = f'{loss.data.item():.4f}'\n",
    "\n",
    "            \n",
    "            path = Path(f'./data/lipinski/results/lstm-1-epoch-{batch_idx}-batch-{print_loss}-loss')\n",
    "            path.mkdir(exist_ok=True)\n",
    "            \n",
    "            torch.save(model.state_dict(), str(path / 'model_dict.torch'))\n",
    "            save(new_smiles, str(path / 'generated_smiles.dict' ))\n",
    "            save(test_loss_history, str(path / 'test_loss.dict' ))\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "    \n",
    "        x_batch, y_batch, batch_lens = batch\n",
    "        \n",
    "        batch_size = x_batch.size(0)\n",
    "        max_len = int(max(batch_lens).item())\n",
    "        \n",
    "        x_batch = x_batch[:, 0:max_len, :]\n",
    "        y_batch = y_batch[:, 0:max_len, :]\n",
    "\n",
    "        # sort input\n",
    "        batch_len_sorted, sort_index = torch.sort(batch_lens, 0, descending=True)\n",
    "        batch_len_sorted = batch_len_sorted.numpy().tolist()\n",
    "        \n",
    "        x_batch = torch.index_select(x_batch, 0, sort_index)\n",
    "        y_batch = torch.index_select(y_batch, 0, sort_index)\n",
    "\n",
    "        x_batch = Variable(x_batch.float()).cuda()\n",
    "        y_batch = Variable(y_batch.float()).cuda()\n",
    "\n",
    "        # init state\n",
    "        model.hidden = model.init_hidden(batch_size=x_batch.size(0))\n",
    "        try:\n",
    "            y_pred = model(x_batch, pack=True, input_lens=batch_len_sorted)\n",
    "        except Exception as e:\n",
    "            print(f'[ERROR] got exception {e}')\n",
    "            print(f'[ERROR] skipping batch...')\n",
    "            continue\n",
    "        \n",
    "        y_pred = F.log_softmax(y_pred.view(-1, NUM_SYM), dim=-1)\n",
    "        _, y_batch = y_batch.topk(1, dim=-1)\n",
    "        y_batch = y_batch.view(-1)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        \n",
    "        print(f'[batch num: {batch_idx}] loss: {loss.data.item():.4f}')\n",
    "                \n",
    "    return loss_history, test_loss_history, new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-b4a44cde6c10>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-b4a44cde6c10>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    P2_SMILES =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "P1_SMILES = (TRAIN_SMILES, TEST_SMILES)\n",
    "P2_SMILES = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning(model, phases):\n",
    "    \"\"\"\n",
    "    transfer_learning(model, phases):\n",
    "        - model: pytorch model\n",
    "        - phases: [Datasets] for datapaths\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_temp_sample(y_t, temperature = 1.0):\n",
    "    prediction_vector = F.softmax(y_t / temperature, dim=-1)\n",
    "    x_index_t = torch.multinomial(prediction_vector, 1)[:, 0]\n",
    "    return x_index_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_sample(y_t):\n",
    "    _, pred_idx =  y_t.topk(1, dim=-1)\n",
    "    return pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, test_samples=5, sample_f=topk_sample, v=True):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        x = torch.zeros(test_samples, MAX_SYM, NUM_SYM).cuda()\n",
    "\n",
    "        x[:, 0, SYM_TO_ID[GO_TOKEN]] = 1\n",
    "        \n",
    "        for i in range(MAX_SYM-1):\n",
    "            model.hidden = model.init_hidden(batch_size=test_samples)\n",
    "            \n",
    "            pred = model(x, pack=True, input_lens=np.ones(test_samples)*(i+1))\n",
    "            pred_idx = sample_f(pred[:,i,:])\n",
    "            temp = torch.zeros(test_samples, MAX_SYM, NUM_SYM).cuda()\n",
    "            for j in range(test_samples):\n",
    "                temp[j, i+1, pred_idx[j]] = 1  \n",
    "            x.add_(temp)\n",
    "\n",
    "        if v: print('\\n',10*'-' + 'GENERATED SMILES STRINGS' + 10*'-')\n",
    "        smiles = []\n",
    "\n",
    "        for j in range(test_samples):\n",
    "            s = decode_short(x[j].cpu().numpy())\n",
    "            smiles += [s]\n",
    "\n",
    "            if v: print(s)\n",
    "\n",
    "        return smiles\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(testloader,total=len(testloader)):\n",
    "\n",
    "            x_batch, y_batch, batch_lens = batch\n",
    "\n",
    "            batch_size = x_batch.size(0)\n",
    "            max_len = int(max(batch_lens).item())\n",
    "\n",
    "            x_batch = x_batch[:, 0:max_len, :]\n",
    "            y_batch = y_batch[:, 0:max_len, :]\n",
    "\n",
    "            # sort input\n",
    "            batch_len_sorted, sort_index = torch.sort(batch_lens, 0, descending=True)\n",
    "            batch_len_sorted = batch_len_sorted.numpy().tolist()\n",
    "\n",
    "            x_batch = torch.index_select(x_batch, 0, sort_index)\n",
    "            y_batch = torch.index_select(y_batch, 0, sort_index)\n",
    "\n",
    "            x_batch = Variable(x_batch.float()).cuda()\n",
    "            y_batch = Variable(y_batch.float()).cuda()\n",
    "\n",
    "            # init state\n",
    "            model.hidden = model.init_hidden(batch_size=x_batch.size(0))\n",
    "\n",
    "            y_pred = model(x_batch, pack=True, input_lens=batch_len_sorted)\n",
    "\n",
    "            y_pred = y_pred.view(-1, NUM_SYM)\n",
    "            _, y_batch = y_batch.topk(1, dim=-1)\n",
    "            y_batch = y_batch.view(-1)\n",
    "\n",
    "            total_loss += criterion(y_pred, y_batch)\n",
    "\n",
    "        return total_loss / len(test_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history, train_history, new_smiles = train_one_epoch(model, model_optim, dataloader, test_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, l=-1):\n",
    "    if l < 0:\n",
    "        l = len(history)\n",
    "    fig = px.line(x=np.arange(l), y=history[:l], labels={'x':'batch number', 'y':'binary cross-entropy loss'})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsmiles = generate(model, test_samples=500, sample_f=softmax_temp_sample, v=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_valid(newsmiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validsmiles = [s for s in newsmiles if Chem.MolFromSmiles(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validsmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmols = [Chem.MolFromSmiles(s) for s in validsmiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qed_mol(m):\n",
    "    properties = ['MW', 'ALOGP', 'HBA', 'HBD', 'PSA', 'ROTB', 'AROM', 'ALERTS']\n",
    "    mol_prop = QED.properties(m)\n",
    "    mol_prop_num = [getattr(mol_prop, attr) for attr in properties]\n",
    "    return mol_prop_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "druglike_mols = [Chem.MolFromSmiles(s[1:]) for s in TEST_SMILES]\n",
    "\n",
    "active_mols = []\n",
    "with open('./data/lipinski/active_lipinski.smi') as fp:\n",
    "    for line in fp.readlines():\n",
    "        active_mols += [Chem.MolFromSmiles(line[:-1])]\n",
    "\n",
    "very_active_mols = []\n",
    "with open('./data/lipinski/very_active_lipinski.smi') as fp:\n",
    "    for line in fp.readlines():\n",
    "        very_active_mols += [Chem.MolFromSmiles(line[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_QED_VALUES = []\n",
    "\n",
    "for mol in tqdm(druglike_mols):\n",
    "    values = ['DRUGLIKE_LIP'] + get_qed_mol(mol)\n",
    "    ALL_QED_VALUES += [values]\n",
    "\n",
    "for mol in tqdm(active_mols):\n",
    "    values = ['ACTIVE_LIP'] + get_qed_mol(mol)\n",
    "    ALL_QED_VALUES += [values]\n",
    "    \n",
    "for mol in tqdm(very_active_mols):\n",
    "    values = ['VERY_ACTIVE_LIP'] + get_qed_mol(mol)\n",
    "    ALL_QED_VALUES += [values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_df = pd.DataFrame(data=ALL_QED_VALUES,columns=['TYPE', 'MW', 'ALOGP', 'HBA', 'HBD', 'PSA', 'ROTB', 'AROM', 'ALERTS' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(mol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_df.to_pickle('./data/lipinski/qed_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qed_data = mol_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qed_data = qed_data.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP(n_components=3)\n",
    "\n",
    "reducer.fit(qed_data)\n",
    "embedding = reducer.transform(qed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = pd.DataFrame(data=embedding,columns=['COMP_1','COMP_2','COMP_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['TYPE'] = mol_df['TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(emb_df, x='COMP_1', y='COMP_2', z='COMP_3',\n",
    "                    color='TYPE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
