{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR, CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice, permutation, randint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit import RDLogger   \n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from statistics import stdev, mean\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPU = 3\n",
    "SEED = 3287450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.empty_cache()\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "RDLogger.DisableLog('rdApp.*') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(thing, path):\n",
    "    with open(path, 'wb') as fp:\n",
    "        pkl.dump(thing, fp)\n",
    "    print(f'saved [{type(thing)}] to {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        thing = pkl.load(fp)\n",
    "    return thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_lipinski.smi\t\t druglike-qed-data.pkl\r\n",
      "active-qed-data.pkl\t\t gcpn_smiles.500.smi\r\n",
      "all_lipinski.smi\t\t lstm_smiles.500.smi\r\n",
      "druglike_lipinski_100k.smi\t qed_df_full.pickle\r\n",
      "druglike_lipinski_10k.smi\t qed_df.pickle\r\n",
      "druglike_lipinski_1k.smi\t qed_df_small.activity.pickle\r\n",
      "druglike_lipinski_50k.test.smi\t results\r\n",
      "druglike_lipinski_50k.train.smi  very_active_lipinski.smi\r\n",
      "druglike_lipinski.smi\t\t very-active-qed-data.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/lipinski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/lipinski/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: \n",
    "        return None\n",
    "    Chem.Kekulize(mol)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smiles_file(path, test_split=0.15):\n",
    "    all_smiles = []\n",
    "    with open(path) as fp:\n",
    "        for line in tqdm(fp.readlines()):\n",
    "            all_smiles += [line[:-1]]\n",
    "    size = len(all_smiles)\n",
    "    split = int(size * test_split)\n",
    "    return all_smiles[split:] ,  all_smiles[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c7017904d84d328beb096f1083a848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "P1_SMILES = process_smiles_file(DATA_PATH / 'druglike_lipinski_1k.smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SMILES = P1_SMILES[0] + P1_SMILES[1] \n",
    "len(ALL_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = Chem.MolFromSmiles(ALL_SMILES[0]) # test mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_seq(G, start_id):\n",
    "    dictionary = dict(nx.bfs_successors(G, start_id))\n",
    "    start = [start_id]\n",
    "    output = [start_id]\n",
    "    while len(start) > 0:\n",
    "        next = []\n",
    "        while len(start) > 0:\n",
    "            current = start.pop(0)\n",
    "            neighbor = dictionary.get(current)\n",
    "            if neighbor is not None:\n",
    "                #### a wrong example, should not permute here!\n",
    "                # shuffle(neighbor)\n",
    "                next = next + neighbor\n",
    "        output = output + next\n",
    "        start = next\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_adj = lambda adj, pi: adj[np.ix_(pi, pi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bfs_ordering(adj, G):\n",
    "    rand_pi = permutation(adj.shape[0])\n",
    "    adj = order_adj(adj, rand_pi)\n",
    "\n",
    "    start_node = randint(adj.shape[0])\n",
    "    G = nx.from_numpy_matrix(adj)\n",
    "\n",
    "    bfs_pi = bfs_seq(G, start_node)\n",
    "    adj = order_adj(adj, bfs_pi)\n",
    "    return bfs_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatype Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atom and Bond Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Br', 'N', 'C', 'S', 'F', 'I', 'P', 'O', 'Cl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELEM_LIST = set()\n",
    "for m in map(Chem.MolFromSmiles, ALL_SMILES):\n",
    "    if m is None: continue\n",
    "\n",
    "    for atom in m.GetAtoms():\n",
    "        ELEM_LIST.add(atom.GetSymbol())\n",
    "        \n",
    "ELEM_LIST = list(ELEM_LIST)\n",
    "ELEM_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOND_TYPES = [Chem.rdchem.BondType.SINGLE, \n",
    "              Chem.rdchem.BondType.DOUBLE, \n",
    "              Chem.rdchem.BondType.TRIPLE, \n",
    "              Chem.rdchem.BondType.AROMATIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOM_FDIM = len(ELEM_LIST) + 6 + 5 + 1\n",
    "BOND_FDIM = len(BOND_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onek_encoding(x, allowable_set):\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def onek_decoding(x, allowable_set):\n",
    "    topi = np.argmax(x)\n",
    "    return allowable_set[topi]\n",
    "    \n",
    "\n",
    "def atom_to_vec(atom):\n",
    "    return torch.Tensor(onek_encoding(atom.GetSymbol(), ELEM_LIST) \n",
    "            + onek_encoding(atom.GetDegree(), [0,1,2,3,4,5]) \n",
    "            + onek_encoding(atom.GetFormalCharge(), [-1, -2, 1, 2, 0])\n",
    "            + [atom.GetIsAromatic()])\n",
    "\n",
    "def bond_to_vec(bond):\n",
    "    bt = bond.GetBondType()\n",
    "    return torch.Tensor(onek_encoding(bt, BOND_TYPES))\n",
    "                         #+[bond.IsInRing()])\n",
    "\n",
    "def vec_to_atom(vec):\n",
    "    atom_type = onek_decoding(vec[:len(ELEM_LIST)], ELEM_LIST)\n",
    "    atom_degree = onek_decoding(vec[len(ELEM_LIST):len(ELEM_LIST) + 6],  [0,1,2,3,4,5])\n",
    "    atom_charge = onek_decoding(vec[len(ELEM_LIST)+6:len(ELEM_LIST)+6+5], [-1, -2, 1, 2, 0])\n",
    "    atom_is_aromatic = int(vec[-1])\n",
    "    \n",
    "    a = Chem.Atom(atom_type)\n",
    "    a.SetFormalCharge(atom_charge)\n",
    "    a.SetIsAromatic(atom_is_aromatic)\n",
    "    \n",
    "    return a\n",
    "def vec_to_bond(vec):\n",
    "    return onek_decoding(vec[:-1], BOND_TYPES)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mol and Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltri(M):\n",
    "    \"\"\"\n",
    "    get_ltri(M):\n",
    "        - pick up lower triangle from matrix with dim(M) = 3\n",
    "    \"\"\"\n",
    "    triM = np.zeros(M.shape)\n",
    "    for f_dim in range(M.shape[-1]):\n",
    "        triM[..., f_dim] = np.tril(M[...,f_dim],k=-1)\n",
    "    return triM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_tensors(mol):\n",
    "    \"\"\"\n",
    "    mol_to_tensor(mol):\n",
    "        - make edge conditioned adjacency matrix --> E\n",
    "        - make atom feature matrix --> F\n",
    "    \"\"\"\n",
    "    n = mol.GetNumAtoms()\n",
    "    E = np.zeros((n, n, BOND_FDIM))\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        s_idx = bond.GetBeginAtomIdx()\n",
    "        e_idx = bond.GetEndAtomIdx()\n",
    "        \n",
    "        bond_enc = bond_to_vec(bond)\n",
    "        E[s_idx, e_idx] = bond_enc\n",
    "        E[e_idx, s_idx] = bond_enc # undirected graph\n",
    "    \n",
    "    F = np.zeros((n, ATOM_FDIM))\n",
    "    for atom_idx, atom in enumerate(mol.GetAtoms()): # order tho\n",
    "        atom_enc = atom_to_vec(atom)\n",
    "        F[atom_idx, :] = atom_enc\n",
    "        \n",
    "    return E, F\n",
    "    \n",
    "def tensors_to_mol(E, F):\n",
    "    global M\n",
    "    \n",
    "    n = E.shape[0]\n",
    "    assert F.shape[0] == n\n",
    "    \n",
    "    mol = Chem.RWMol()\n",
    "    node_to_idx = dict()\n",
    "    \n",
    "    for n_idx in range(n):\n",
    "        atom_enc = F[n_idx, :]\n",
    "        atom = vec_to_atom(atom_enc)\n",
    "        atom_idx = mol.AddAtom(atom)\n",
    "        node_to_idx[n_idx] = atom_idx\n",
    "        \n",
    "    E = get_ltri(E)\n",
    "    row_idxs, col_idxs = np.nonzero(edges.sum(dim=-1))\n",
    "    \n",
    "    for row, col in zip(row_idxs, col_idxs):\n",
    "        bond_vec = E[row, col]\n",
    "        bond_type = vec_to_bond(bond_vec)\n",
    "        \n",
    "        start_atom = node_to_idx[row]\n",
    "        end_atom = node_to_idx[col]\n",
    "        \n",
    "        mol.AddBond(start_atom, end_atom, bond_type)\n",
    "        \n",
    "    Chem.SanitizeMol(mol)\n",
    "    return mol\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mol and Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_adj(mol):\n",
    "    return nx.to_numpy_array(mol_to_nx(mol))\n",
    "\n",
    "def mol_to_nx(mol):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "        G.add_node(atom.GetIdx(),\n",
    "                   atomic_num=atom.GetAtomicNum(),\n",
    "                   formal_charge=atom.GetFormalCharge(),\n",
    "                   chiral_tag=atom.GetChiralTag(),\n",
    "                   hybridization=atom.GetHybridization(),\n",
    "                   num_explicit_hs=atom.GetNumExplicitHs(),\n",
    "                   is_aromatic=atom.GetIsAromatic())\n",
    "    for bond in mol.GetBonds():\n",
    "        G.add_edge(bond.GetBeginAtomIdx(),\n",
    "                   bond.GetEndAtomIdx(),\n",
    "                   bond_type=bond.GetBondType())\n",
    "    return G\n",
    "\n",
    "\n",
    "def nx_to_mol(G):\n",
    "    mol = Chem.RWMol()\n",
    "    atomic_nums = nx.get_node_attributes(G, 'atomic_num')\n",
    "    chiral_tags = nx.get_node_attributes(G, 'chiral_tag')\n",
    "    formal_charges = nx.get_node_attributes(G, 'formal_charge')\n",
    "    node_is_aromatics = nx.get_node_attributes(G, 'is_aromatic')\n",
    "    node_hybridizations = nx.get_node_attributes(G, 'hybridization')\n",
    "    num_explicit_hss = nx.get_node_attributes(G, 'num_explicit_hs')\n",
    "    node_to_idx = {}\n",
    "    for node in G.nodes():\n",
    "        a = Chem.Atom(atomic_nums[node])\n",
    "        a.SetChiralTag(chiral_tags[node])\n",
    "        a.SetFormalCharge(formal_charges[node])\n",
    "        a.SetIsAromatic(node_is_aromatics[node])\n",
    "        a.SetHybridization(node_hybridizations[node])\n",
    "        a.SetNumExplicitHs(num_explicit_hss[node])\n",
    "        idx = mol.AddAtom(a)\n",
    "        node_to_idx[node] = idx\n",
    "\n",
    "    bond_types = nx.get_edge_attributes(G, 'bond_type')\n",
    "    for edge in G.edges():\n",
    "        first, second = edge\n",
    "        ifirst = node_to_idx[first]\n",
    "        isecond = node_to_idx[second]\n",
    "        bond_type = bond_types[first, second]\n",
    "        mol.AddBond(ifirst, isecond, bond_type)\n",
    "\n",
    "    Chem.SanitizeMol(mol)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph, MolTensors and SequenceTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_to_seq(adj):\n",
    "    \"\"\"\n",
    "    adj_to_seq_tensor(adj, M):\n",
    "         - requires M which is emprically calculated max prev node\n",
    "         - adj is a adjacency matrix dim(A) = (n-1, n-1) \n",
    "           also adj only has values in the lower triangle\n",
    "    returns: sequence tensor S dim(S) = (n, M) \n",
    "    \"\"\"\n",
    "    global M\n",
    "\n",
    "    n = adj.shape[0]\n",
    "    f_dim = adj.shape[-1]\n",
    "    \n",
    "    if len(adj.shape) == 3:\n",
    "        S = np.zeros((n, M, f_dim))\n",
    "    else:\n",
    "        S = np.zeros((n, M))\n",
    "    \n",
    "    for i in range(n):\n",
    "        input_start = max(0, i - M + 1)\n",
    "        input_end = i + 1\n",
    "        \n",
    "        output_start = M + input_start - input_end\n",
    "        output_end = M\n",
    "        \n",
    "        S[i, output_start:output_end] = adj[i, input_start:input_end]\n",
    "        S[i, :] = S[i, :][::-1]\n",
    "        \n",
    "    return S\n",
    "\n",
    "\n",
    "def seq_to_adj(S):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    global M\n",
    "    n = S.shape[0]\n",
    "    f_dim = S.shape[-1]\n",
    "    \n",
    "    if len(S.shape) == 3:\n",
    "        adj = np.zeros((n, n, f_dim))\n",
    "    else:\n",
    "        adj = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        \n",
    "        input_start = max(0, i - M + 1)\n",
    "        input_end = i + 1\n",
    "        \n",
    "        output_start = M + max(0, i - M + 1) - (i + 1)\n",
    "        output_end = M\n",
    "        \n",
    "        adj[i, input_start:input_end] = S[i,::-1][output_start:output_end] # reverse order\n",
    "        \n",
    "    adj_full = np.zeros((n+1, n+1))\n",
    "    n = adj_full.shape[0]\n",
    "    adj_full[1:n, 0:n-1] = np.tril(adj, 0)\n",
    "    adj_full = adj_full + adj_full.T\n",
    "\n",
    "    return adj_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj = np.array([[1, 0, 0],\n",
    "#                 [0, 1, 0],\n",
    "#                 [0, 1, 1]])\n",
    "# M = 5\n",
    "# print(f'OG adj (ltril, cut): \\n{adj}')\n",
    "# print(f'recovered adj:\\n{seq_to_adj(adj_to_seq(adj))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Transform Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_transform(mol):\n",
    "    G = mol_to_nx(mol)\n",
    "    E, F = mol_to_tensors(mol)\n",
    "    \n",
    "    bfs_order = get_bfs_ordering(E.sum(axis=-1), G)\n",
    "    E = order_adj(E, bfs_order)\n",
    "    F = F[bfs_order]\n",
    "    \n",
    "    S = adj_to_seq(E)\n",
    "    return S, F\n",
    "\n",
    "def backward_transform(S, F):\n",
    "    E = seq_to_adj(S)\n",
    "    return tensors_to_mol(E, F)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Max Prev Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function amin in module numpy:\n",
      "\n",
      "amin(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n",
      "    Return the minimum of an array or minimum along an axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, the minimum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See `ufuncs-output-type` for more details.\n",
      "    \n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amin` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    initial : scalar, optional\n",
      "        The maximum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.15.0\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    amin : ndarray or scalar\n",
      "        Minimum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is given, the result is an array of dimension\n",
      "        ``a.ndim - 1``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    amax :\n",
      "        The maximum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmin :\n",
      "        The minimum value of an array along a given axis, ignoring any NaNs.\n",
      "    minimum :\n",
      "        Element-wise minimum of two arrays, propagating any NaNs.\n",
      "    fmin :\n",
      "        Element-wise minimum of two arrays, ignoring any NaNs.\n",
      "    argmin :\n",
      "        Return the indices of the minimum values.\n",
      "    \n",
      "    nanmax, maximum, fmax\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding min value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmin.\n",
      "    \n",
      "    Don't use `amin` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than\n",
      "    ``amin(a, axis=0)``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amin(a)           # Minimum of the flattened array\n",
      "    0\n",
      "    >>> np.amin(a, axis=0)   # Minima along the first axis\n",
      "    array([0, 1])\n",
      "    >>> np.amin(a, axis=1)   # Minima along the second axis\n",
      "    array([0, 2])\n",
      "    >>> np.amin(a, where=[False, True], initial=10, axis=0)\n",
      "    array([10,  1])\n",
      "    \n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amin(b)\n",
      "    nan\n",
      "    >>> np.amin(b, where=~np.isnan(b), initial=10)\n",
      "    0.0\n",
      "    >>> np.nanmin(b)\n",
      "    0.0\n",
      "    \n",
      "    >>> np.min([[-50], [10]], axis=-1, initial=0)\n",
      "    array([-50,   0])\n",
      "    \n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    minimum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "    \n",
      "    Notice that this isn't the same as Python's ``default`` argument.\n",
      "    \n",
      "    >>> np.min([6], initial=5)\n",
      "    5\n",
      "    >>> min([6], default=5)\n",
      "    6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.amin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_adj_flexible(adj):\n",
    "    # get rid of duplicate info\n",
    "    adj = np.tril(adj, k=-1)\n",
    "    n = adj.shape[0]\n",
    "    adj = adj[1:n, 0:n-1]\n",
    "\n",
    "    adj_output = []\n",
    "    input_start = 0\n",
    "    for i in range(adj.shape[0]):\n",
    "        input_end = i + 1\n",
    "        adj_slice = adj[i, input_start:input_end]\n",
    "        \n",
    "        adj_output.append(adj_slice)\n",
    "        non_zero = np.nonzero(adj_slice)[0]\n",
    "        print(non_zero)\n",
    "        input_start = input_end-len(adj_slice)+np.amin(non_zero)\n",
    "\n",
    "    return adj_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_prev_nodes(smiles):\n",
    "    max_ms = []\n",
    "    for s in tqdm(smiles):\n",
    "        mol = get_mol(s)\n",
    "        \n",
    "        if mol is None: \n",
    "            continue\n",
    "            \n",
    "        G = mol_to_nx(mol)\n",
    "        adj = nx.to_numpy_array(G)\n",
    "        \n",
    "        bfs_pi = get_bfs_ordering(adj, G)\n",
    "        adj = order_adj(adj, bfs_pi)\n",
    "        \n",
    "        print(adj)\n",
    "        adj_slices = encode_adj_flexible(adj)\n",
    "        max_m = max(map(len, adj_slices))\n",
    "        max_ms += [max_m]\n",
    "        \n",
    "    return max(max_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8c3b89df854c11a35bbbbfac5d068d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "0\n",
      "[]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b0f7a60d7634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_max_prev_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALL_SMILES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-bf4016907dd4>\u001b[0m in \u001b[0;36mcompute_max_prev_nodes\u001b[0;34m(smiles)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0madj_slices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_adj_flexible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmax_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmax_ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-e40ee9ee1555>\u001b[0m in \u001b[0;36mencode_adj_flexible\u001b[0;34m(adj)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnon_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0minput_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madj_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pymatch/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \"\"\"\n\u001b[1;32m   2792\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0;32m-> 2793\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pymatch/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "M = compute_max_prev_nodes(ALL_SMILES)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL TRANSFORM TEST\n",
    "S, F = forward_transform(tmol)\n",
    "tmol_back = backward_transform(S, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, smiles):\n",
    "        self.all_smiles = smiles\n",
    "        self.size = len(smiles)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        __getitem__(self, i):\n",
    "            - return \n",
    "        \"\"\"\n",
    "        x_i, x_n = encode(self.all_smiles[i])\n",
    "        \n",
    "        y_i = x_i[1:].copy()\n",
    "        x_i = x_i[:-1].copy()\n",
    "        \n",
    "        return x_i, y_i, x_n\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TransferLearning Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_phase(data, pid, lr, interval, ):\n",
    "    Phase = namedtuple('Phase', ['pid', 'traindata', 'testdata', 'lr', 'test_interval'])\n",
    "    phase = Phase(traindata=SMILESDataset(data[0]),\n",
    "                  testdata=SMILESDataset(data[1]),\n",
    "                  lr=lr,\n",
    "                  pid=pid, # phase id\n",
    "                  test_interval=interval)\n",
    "    \n",
    "    return phase\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LR_BASE = 3e-3\n",
    "P1 = make_phase(P1_SMILES, 1, 3e-3/2, 500)\n",
    "P2 = make_phase(P2_SMILES, 2,3e-4, 100)\n",
    "P3 = make_phase(P3_SMILES, 3, 3e-4/2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plain LSTM model\n",
    "class GeneratorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size, embedding_size, bidirectional):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=0.15,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        self.input_module = nn.Sequential(nn.Linear(input_size, 256),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.10),\n",
    "                                         nn.Linear(256, 512),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.10),\n",
    "                                         nn.Linear(512, embedding_size),\n",
    "                                         nn.ReLU())\n",
    "        lstm_output_shape = hidden_size if not bidirectional else hidden_size * 2\n",
    "        self.output_module = nn.Sequential(nn.Linear(lstm_output_shape , 256),\n",
    "                                           nn.Dropout(0.10),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(256, output_size))\n",
    "\n",
    "        self.hidden = None \n",
    "\n",
    "    def init_hidden(self, batch_size, cuda=True):\n",
    "        if self.bidirectional:\n",
    "            ht = Variable(torch.zeros(self.num_layers*2, batch_size, self.hidden_size))\n",
    "            ct = Variable(torch.zeros(self.num_layers*2, batch_size, self.hidden_size))\n",
    "        else:\n",
    "            ht = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "            ct = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "            \n",
    "\n",
    "        if cuda:\n",
    "            return ht.cuda(), ct.cuda()\n",
    "        else:\n",
    "            return ht, ct\n",
    "            \n",
    "\n",
    "\n",
    "    def forward(self, input_raw, pack=False, input_lens=None):\n",
    "        \"\"\"\n",
    "        forward(self, input_raw, state):\n",
    "             - input_raw = (bs, x_{i,t})\n",
    "             - state = (ht, ct)\n",
    "        \"\"\"\n",
    "        input_ = self.input_module(input_raw)\n",
    "        \n",
    "        if pack:\n",
    "            input_ = pack_padded_sequence(input_, input_lens, batch_first=True)\n",
    "            \n",
    "        input_, self.hidden = self.lstm(input_, self.hidden)\n",
    "        \n",
    "        if pack: \n",
    "            input_ = pad_packed_sequence(input_, batch_first=True)[0]\n",
    "\n",
    "            \n",
    "        input_ = self.output_module(input_)\n",
    "        return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GeneratorLSTM(input_size = NUM_SYM, \n",
    "                      output_size = NUM_SYM, \n",
    "                      num_layers = 3, \n",
    "                      hidden_size = 512, \n",
    "                      embedding_size = 512,\n",
    "                      bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'model has [{count_parameters(model):,}] trainable params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, model_optim, lr_sched,\n",
    "                    train_dataloader, test_dataloader, \n",
    "                    test_interval, save_path, epoch):\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    loss_history = []\n",
    "    total = len(train_dataloader)\n",
    "    \n",
    "    test_loss_history = defaultdict(list)\n",
    "    new_smiles = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for batch_idx, batch in tqdm(enumerate(train_dataloader), total=total):\n",
    "        \n",
    "        if batch_idx % test_interval == 0:\n",
    "            new_smiles[batch_idx] = generate(model,)\n",
    "            \n",
    "            smiles_valid_batch = generate(model, test_samples=100, sample_f=softmax_temp_sample, v=False)\n",
    "            validity = count_valid(smiles_valid_batch)\n",
    "            \n",
    "            test_loss_history[batch_idx] = test(model, test_dataloader)\n",
    "            # we can test later\n",
    "            \n",
    "            print(f'[batch num: {batch_idx}] sampled; [{validity:.3f}%] valid smiles sampled')\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                print_loss = 'nan'\n",
    "            else:\n",
    "                print_loss = f'{loss.data.item():.4f}'\n",
    "\n",
    "            \n",
    "            path = save_path / Path(f'{epoch}-epoch-{batch_idx}-batch-{print_loss}-loss')\n",
    "            path.mkdir(exist_ok=True)\n",
    "            \n",
    "            torch.save(model.state_dict(), str(path / 'model_dict.torch'))\n",
    "            save(new_smiles[batch_idx], str(path / 'generated_smiles.list' ))\n",
    "            save(test_loss_history[batch_idx] , str(path / 'test_loss.item' ))\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "    \n",
    "        x_batch, y_batch, batch_lens = batch\n",
    "        \n",
    "        batch_size = x_batch.size(0)\n",
    "        max_len = int(max(batch_lens).item())\n",
    "        \n",
    "        x_batch = x_batch[:, 0:max_len, :]\n",
    "        y_batch = y_batch[:, 0:max_len, :]\n",
    "\n",
    "        # sort input\n",
    "        batch_len_sorted, sort_index = torch.sort(batch_lens, 0, descending=True)\n",
    "        batch_len_sorted = batch_len_sorted.numpy().tolist()\n",
    "        \n",
    "        x_batch = torch.index_select(x_batch, 0, sort_index)\n",
    "        y_batch = torch.index_select(y_batch, 0, sort_index)\n",
    "\n",
    "        x_batch = Variable(x_batch.float()).cuda()\n",
    "        y_batch = Variable(y_batch.float()).cuda()\n",
    "\n",
    "        # init state\n",
    "        model.hidden = model.init_hidden(batch_size=x_batch.size(0))\n",
    "        try:\n",
    "            y_pred = model(x_batch, pack=True, input_lens=batch_len_sorted)\n",
    "        except Exception as e:\n",
    "            print(f'[ERROR] got exception {e}')\n",
    "            print(f'[ERROR] skipping batch...')\n",
    "            continue\n",
    "        \n",
    "        y_pred = F.log_softmax(y_pred.view(-1, NUM_SYM), dim=-1)\n",
    "        _, y_batch = y_batch.topk(1, dim=-1)\n",
    "        y_batch = y_batch.view(-1)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        lr_sched.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 10 == 0 :\n",
    "            print(f'[batch num: {batch_idx}] loss: {loss.data.item():.4f}')\n",
    "            \n",
    "    path = save_path / Path(f'{epoch}-epoch-END-batch')\n",
    "    path.mkdir(exist_ok=True)\n",
    "\n",
    "    torch.save(model.state_dict(), str(path / 'model_dict.torch'))\n",
    "\n",
    "                \n",
    "    return loss_history, test_loss_history, new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_run_id():\n",
    "    return  np.random.choice(['cheetah', 'jaguar', 'wombat', 'cobra', \n",
    "                               'croc', 'panda', 'dragon', 'seal', 'spider', 'lizard',\n",
    "                               'gorilla', 'koala', 'blackbear', 'grizzly', 'zebra',\n",
    "                               'hippo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_run_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transfer_learning(model, phases, epochs, batch_size=32, run_id = None):\n",
    "    \"\"\"\n",
    "    transfer_learning(model, phases):\n",
    "        - model: pytorch model\n",
    "        - phases: [Datasets] for datapaths\n",
    "    \"\"\"\n",
    "    history = defaultdict(dict)\n",
    "    \n",
    "    run_id = run_id if run_id is not None else make_run_id()\n",
    "    \n",
    "    results_dir = DATA_PATH / 'results' / f'{run_id}-run'\n",
    "    results_dir.mkdir(exist_ok=False)\n",
    "    save(SYM_TO_ID, results_dir / 'SYM_TO_ID')\n",
    "    save(ID_TO_SYM, results_dir / 'ID_TO_SYM')\n",
    "\n",
    "    print(f'[TRANSFER_LEARNER] saving all progress to [{results_dir}]')\n",
    "    \n",
    "    for idx, phase in enumerate(phases):\n",
    "        print(f'[TRANSFER_LEARNER] STARTING PHASE [{phase.pid}]')\n",
    "        \n",
    "        dataloader = DataLoader(phase.traindata, \n",
    "                                batch_size=batch_size, \n",
    "                                num_workers=NUM_CPU, \n",
    "                                shuffle=True)\n",
    "        \n",
    "        testloader = DataLoader(phase.testdata, \n",
    "                                batch_size=1000, \n",
    "                                num_workers=NUM_CPU, \n",
    "                                shuffle=True)\n",
    "        \n",
    "        model_optim = optim.Adam(list(model.parameters()), lr=phase.lr)\n",
    "        lr_sched = CosineAnnealingLR(model_optim, 500)\n",
    "        \n",
    "        phase_dir = results_dir / f'phase-{phase.pid}'\n",
    "        phase_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for epoch_idx in range(epochs[idx]):\n",
    "            print(f'[TRANSFER_LEARNER] PHASE [{phase.pid}] EPOCH [{epoch_idx}]')\n",
    "            history[phase.pid][epoch_idx] = train_one_epoch(model, model_optim, lr_sched,\n",
    "                                                   dataloader, testloader,\n",
    "                                                   phase.test_interval, phase_dir, \n",
    "                                                   epoch_idx)\n",
    "            \n",
    "    return history\n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Testing and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax_temp_sample(y_t, temperature = 1.0):\n",
    "    prediction_vector = F.softmax(y_t / temperature, dim=-1)\n",
    "    x_index_t = torch.multinomial(prediction_vector, 1)[:, 0]\n",
    "    return x_index_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def topk_sample(y_t):\n",
    "    _, pred_idx =  y_t.topk(1, dim=-1)\n",
    "    return pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate(model, test_samples=5, sample_f=softmax_temp_sample, v=True):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        x = torch.zeros(test_samples, MAX_SYM, NUM_SYM).cuda()\n",
    "\n",
    "        x[:, 0, SYM_TO_ID[GO_TOKEN]] = 1\n",
    "        \n",
    "        for i in range(MAX_SYM-1):\n",
    "            model.hidden = model.init_hidden(batch_size=test_samples)\n",
    "            \n",
    "            pred = model(x, pack=True, input_lens=np.ones(test_samples)*(i+1))\n",
    "            pred_idx = sample_f(pred[:,i,:])\n",
    "            temp = torch.zeros(test_samples, MAX_SYM, NUM_SYM).cuda()\n",
    "            for j in range(test_samples):\n",
    "                temp[j, i+1, pred_idx[j]] = 1  \n",
    "            x.add_(temp)\n",
    "\n",
    "        if v: print('\\n',10*'-' + 'GENERATED SMILES STRINGS' + 10*'-')\n",
    "        smiles = []\n",
    "\n",
    "        for j in range(test_samples):\n",
    "            s = decode_valid(x[j].cpu().numpy())\n",
    "            smiles += [s]\n",
    "\n",
    "            if v: print(s)\n",
    "\n",
    "        return smiles\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(model, testloader):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(testloader,total=len(testloader)):\n",
    "\n",
    "            x_batch, y_batch, batch_lens = batch\n",
    "\n",
    "            batch_size = x_batch.size(0)\n",
    "            max_len = int(max(batch_lens).item())\n",
    "\n",
    "            x_batch = x_batch[:, 0:max_len, :]\n",
    "            y_batch = y_batch[:, 0:max_len, :]\n",
    "\n",
    "            # sort input\n",
    "            batch_len_sorted, sort_index = torch.sort(batch_lens, 0, descending=True)\n",
    "            batch_len_sorted = batch_len_sorted.numpy().tolist()\n",
    "\n",
    "            x_batch = torch.index_select(x_batch, 0, sort_index)\n",
    "            y_batch = torch.index_select(y_batch, 0, sort_index)\n",
    "\n",
    "            x_batch = Variable(x_batch.float()).cuda()\n",
    "            y_batch = Variable(y_batch.float()).cuda()\n",
    "\n",
    "            # init state\n",
    "            model.hidden = model.init_hidden(batch_size=x_batch.size(0))\n",
    "\n",
    "            y_pred = model(x_batch, pack=True, input_lens=batch_len_sorted)\n",
    "\n",
    "            y_pred = y_pred.view(-1, NUM_SYM)\n",
    "            _, y_batch = y_batch.topk(1, dim=-1)\n",
    "            y_batch = y_batch.view(-1)\n",
    "\n",
    "            total_loss += criterion(y_pred, y_batch)\n",
    "\n",
    "        return total_loss.data.item() / len(testloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = transfer_learning(model, phases=[P1, P2, P3], epochs=[2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, l=-1):\n",
    "    if l < 0:\n",
    "        l = len(history)\n",
    "    fig = px.line(x=np.arange(l), y=history[:l], labels={'x':'batch number', 'y':'binary cross-entropy loss'})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls data/lipinski/results/panda-run/phase-0/0-epoch-3500-batch-0.4833-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load('data/lipinski/results/panda-run/phase-0/0-epoch-3500-batch-0.4833-loss/generated_smiles.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_path = './data/lipinski/results/panda-run/phase-0/0-epoch-3500-batch-0.4833-loss/model_dict.torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "newsmiles = generate(model, test_samples=500, sample_f=softmax_temp_sample)\n",
    "validity = count_valid(newsmiles)\n",
    "print(f'validity is at [{validity:.2f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transfer_learning(model, [P2, P3], [2, 2] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
